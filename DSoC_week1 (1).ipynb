{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBsgox_mlkHo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3222dbfd-4c79-4533-faee-fbcda2b44f1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n",
            "None\n",
            "Time        float64\n",
            "V1          float64\n",
            "V2          float64\n",
            "V3          float64\n",
            "V4          float64\n",
            "V5          float64\n",
            "V6          float64\n",
            "V7          float64\n",
            "V8          float64\n",
            "V9          float64\n",
            "V10         float64\n",
            "V11         float64\n",
            "V12         float64\n",
            "V13         float64\n",
            "V14         float64\n",
            "V15         float64\n",
            "V16         float64\n",
            "V17         float64\n",
            "V18         float64\n",
            "V19         float64\n",
            "V20         float64\n",
            "V21         float64\n",
            "V22         float64\n",
            "V23         float64\n",
            "V24         float64\n",
            "V25         float64\n",
            "V26         float64\n",
            "V27         float64\n",
            "V28         float64\n",
            "Amount      float64\n",
            "newClass    float64\n",
            "dtype: object\n",
            "Number of NaN values in 'y' before handling: 1079\n",
            "Accuracy: 0.7137963119607511\n",
            "Precision: 0.0027587565889945318\n",
            "Recall: 0.49122807017543857\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "import numpy as np\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "print(df.info())\n",
        "df_no_duplicates = df.drop_duplicates()\n",
        "w=df_no_duplicates.copy()\n",
        "w['newClass'] = w['Class'].astype(float)\n",
        "newdf = w.drop(\"Class\", axis='columns')\n",
        "print(newdf.dtypes)\n",
        "target_column = 'newClass'\n",
        "df_to_scale = newdf.drop(columns=[target_column])\n",
        "scaler = StandardScaler()\n",
        "\n",
        "scaled_data = scaler.fit_transform(df_to_scale)\n",
        "df_scaled = pd.DataFrame(scaled_data, columns=df_to_scale.columns)\n",
        "df_scaled[target_column] = newdf[target_column]\n",
        "X=df_scaled.drop(columns=[target_column])\n",
        "y=df_scaled[target_column]\n",
        "\n",
        "\n",
        "print(f\"Number of NaN values in 'y' before handling: {y.isna().sum()}\")\n",
        "\n",
        "\n",
        "y = y.fillna(y.median())\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=16)\n",
        "logreg = LogisticRegression(random_state=16, class_weight='balanced')\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "cnf_matrix = metrics.confusion_matrix(y_test, y_pred)\n",
        "cnf_matrix\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Modelling\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Tree Visualisation\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import Image\n",
        "import graphviz\n",
        "df = pd.read_csv('creditcard.csv')\n",
        "df_no_duplicates = df.drop_duplicates()\n",
        "w=df_no_duplicates.copy()\n",
        "w['newClass'] = w['Class'].astype(float)\n",
        "newdf = w.drop(\"Class\", axis='columns')\n",
        "\n",
        "target_column = 'newClass'\n",
        "X=newdf.drop(columns=[target_column])\n",
        "y=newdf[target_column]\n",
        "param_dist = {'n_estimators': randint(25,50),\n",
        "              'max_depth': randint(1,10)}\n",
        "\n",
        "# Create a random forest classifier\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Use random search to find the best hyperparameters\n",
        "rand_search = RandomizedSearchCV(rf,\n",
        "                                 param_distributions = param_dist,\n",
        "                                 n_iter=5,\n",
        "                                 cv=5)\n",
        "\n",
        "# Fit the random search object to the data\n",
        "rand_search.fit(X_train, y_train)\n",
        "\n",
        "y_pred = rand_search.predict(X_test)\n",
        "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
        "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "VTvU24RNmmlc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}